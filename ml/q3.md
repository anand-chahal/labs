# **Coding Lab: Polynomial Regression in Python**  

### **Objective**  
In this lab, you will:  
- Understand when polynomial regression is needed  
- Generate non-linear data  
- Train a **Polynomial Regression** model using `scikit-learn`  
- Compare it with Linear Regression  
- Visualize the results  

---

## **Step 1: Import Required Libraries**  


## **Step 2: Create a Non-Linear Dataset**  
We generate data where `y` follows a **quadratic relationship** with `X`.  
```python
np.random.seed(42)

# Generate feature variable
X = 6 * np.random.rand(100, 1) - 3  # Values in range [-3, 3]

# Generate non-linear target variable
y = 1 + 2 * X + 3 * X**2 + np.random.randn(100, 1) * 2  # Quadratic relationship with noise

# Convert to DataFrame
data = pd.DataFrame(np.hstack((X, y)), columns=['X', 'y'])
```

---

## **Step 3: Visualizing the Data**  


---

## **Step 4: Split the Data into Training and Testing Sets**  


## **Step 5: Train a Linear Regression Model**  
First, we train a **Linear Regression** model to see why it struggles with non-linear data.  
---

## **Step 6: Train a Polynomial Regression Model**  
Now, we transform the feature `X` to include polynomial terms and fit a model.  


---

## **Step 7: Visualizing the Results**  


---

# **Questions**

## **Coding Question**  
1. Implement a function `train_polynomial_regression(X_train, y_train, degree)` that trains a polynomial regression model and returns the trained model.  

## **Conceptual Questions**  
2. Why does **Linear Regression** fail for this dataset?  
3. How does the `PolynomialFeatures` transformer work in `scikit-learn`?  
4. What are the risks of choosing a **high-degree polynomial** for regression?  
5. How can we determine the best polynomial degree for a given dataset?  
6. If polynomial regression is still performing poorly, what preprocessing steps can help improve the model?  