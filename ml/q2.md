# **Coding Lab: Multivariate Linear Regression in Python**

### **Objective**
In this lab, you will:  
- Load and explore a dataset using `pandas`  
- Train a **Multivariate Linear Regression** model using `scikit-learn`  
- Evaluate the modelâ€™s performance  
- Visualize results  

### **Step 1: Import Required Libraries**  

### **Step 2: Create a Synthetic Dataset**  
We simulate a dataset where `y` depends on **two features** `X1` and `X2`.  
```python
np.random.seed(42)

# Generate two independent variables
X1 = 2 * np.random.rand(100, 1)
X2 = 3 * np.random.rand(100, 1)

# Generate the dependent variable with some noise
y = 5 + 2 * X1 + 3 * X2 + np.random.randn(100, 1)

# Create DataFrame
data = pd.DataFrame(np.hstack((X1, X2, y)), columns=['X1', 'X2', 'y'])
```

### **Step 3: Split the Data into Training and Testing Sets**  

### **Step 4: Train a Multivariate Linear Regression Model**  

### **Step 5: Make Predictions and Evaluate the Model**  

### **Step 6: 3D Visualization of the Regression Plane**  

# **Questions**

## **Conceptual Questions**  
1. Why do we need **multiple features** in regression? How does adding more features impact the model?  
2. How does the `LinearRegression` model in `scikit-learn` compute the best-fit coefficients?  
3. What is **multicollinearity**, and how can it affect a linear regression model?  
4. What happens if one of the features in the dataset is completely uncorrelated with the target variable?  
5. If the Mean Squared Error (MSE) is high, what steps can you take to improve the model?  